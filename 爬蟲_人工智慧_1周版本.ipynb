{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JIQNeXsXlCyL",
        "LDy5S0zDlFLk"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j7tfj7f8k1f/Automatic-testing-tools/blob/main/%E7%88%AC%E8%9F%B2_%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7_1%E5%91%A8%E7%89%88%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GITHUB關於AI 爬蟲一周份量"
      ],
      "metadata": {
        "id": "JIQNeXsXlCyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K5Bmn84d3VJ",
        "outputId": "f6b30e1e-7b25-401b-c7cf-a2b11f09871a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在抓取過去一週內的人工智慧相關資料庫...\n",
            "正在篩選真正的人工智慧工具資料庫...\n",
            "Could not fetch README for Wireless-sensor-network-based-train-to-train-imparting-system-: 404\n",
            "Could not fetch README for L-T-EduTech: 404\n",
            "Could not fetch README for Concepts-of-AI-and-Machine-Learning: 404\n",
            "Could not fetch README for Data-Analysis: 404\n",
            "Could not fetch README for distill: 404\n",
            "Could not fetch README for COSC-4368-Final-Project: 404\n",
            "Could not fetch README for Predicting-Diabetes-Progression: 404\n",
            "Could not fetch README for LLCB: 404\n",
            "Could not fetch README for react-vite-antd-showcase-: 404\n",
            "Could not fetch README for AI-and-ML: 404\n",
            "Could not fetch README for Heart-Disease-Prediction: 404\n",
            "Could not fetch README for SETI-ET-Signals: 404\n",
            "Could not fetch README for Neural_network: 404\n",
            "Could not fetch README for nncartpole: 404\n",
            "Could not fetch README for Life_Xacker: 404\n",
            "Could not fetch README for aaai2025-fattnn: 404\n",
            "Could not fetch README for American-Sign-Language-Alphabets-Recognition-Using-Computer-Vision: 404\n",
            "Could not fetch README for MLP-num-sequences: 404\n",
            "Could not fetch README for BeeAntClassifier: 404\n",
            "Could not fetch README for DigitRecognition: 404\n",
            "Could not fetch README for Fortnite-Neural-Network: 404\n",
            "Could not fetch README for cnn-classification: 404\n",
            "Could not fetch README for NeuralNetwork: 404\n",
            "Could not fetch README for NeuralNetworkFromScratch: 404\n",
            "Could not fetch README for Digit-Recognizer-Neural-Network: 404\n",
            "Could not fetch README for VisionCursor: 404\n",
            "Could not fetch README for Pose-detection-cv: 404\n",
            "Could not fetch README for American-Sign-Language-Alphabets-Recognition-Using-Computer-Vision: 404\n",
            "Could not fetch README for Computer-vision: 404\n",
            "Could not fetch README for Computer-Vision: 404\n",
            "Could not fetch README for 500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code-main: 404\n",
            "Could not fetch README for CV: 404\n",
            "Could not fetch README for AppliedAILab: 404\n",
            "Could not fetch README for MNIST_Conv_NN: 404\n",
            "Could not fetch README for Computer-Vision: 404\n",
            "Could not fetch README for Computer-Vision: 404\n",
            "Could not fetch README for computer_vision---Transformer: 404\n",
            "Could not fetch README for example-scripts-computervision: 404\n",
            "Could not fetch README for ComputerVision-Major: 404\n",
            "Could not fetch README for ai-in-python: 404\n",
            "Could not fetch README for compvis-project: 404\n",
            "Could not fetch README for Computer-Vision-Practice: 404\n",
            "Could not fetch README for ASLai: 404\n",
            "Could not fetch README for faceMesh: 404\n",
            "Could not fetch README for HAND_DETECTION: 404\n",
            "已成功將 135 筆資料儲存到 github_ai_repositories.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import csv\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def fetch_repositories():\n",
        "    # GitHub API URL\n",
        "    base_url = \"https://api.github.com/search/repositories\"\n",
        "\n",
        "    # 計算過去一週的日期\n",
        "    one_week_ago = datetime.utcnow() - timedelta(days=7)\n",
        "    date_query = one_week_ago.strftime('%Y-%m-%d')\n",
        "\n",
        "    # 查詢關鍵字分組，避免超過 GitHub API 限制\n",
        "    keyword_groups = [\n",
        "        \"artificial intelligence OR machine learning OR deep learning\",\n",
        "        \"neural network OR AI OR NLP\",\n",
        "        \"GAN OR reinforcement learning OR computer vision\"\n",
        "    ]\n",
        "\n",
        "    repositories = []\n",
        "\n",
        "    # 在這裡輸入你的 GitHub Personal Access Token\n",
        "    headers = {\n",
        "        'Authorization': 'token 這是GITHUBAPIKEY貼上的地方'\n",
        "    }\n",
        "\n",
        "    for group in keyword_groups:\n",
        "        params = {\n",
        "            'q': f'created:>{date_query} ({group})',\n",
        "            'sort': 'stars',\n",
        "            'order': 'desc',\n",
        "            'per_page': 100\n",
        "        }\n",
        "\n",
        "        # 送出 API 請求\n",
        "        response = requests.get(base_url, headers=headers, params=params)\n",
        "\n",
        "        # 確保請求成功\n",
        "        if response.status_code == 200:\n",
        "            repositories.extend(response.json()['items'])\n",
        "        else:\n",
        "            print(f\"Error: {response.status_code} - {response.text}\")\n",
        "\n",
        "    return repositories\n",
        "\n",
        "def is_ai_related(readme_content):\n",
        "    keywords = ['model', 'training', 'inference', 'API', 'AI', 'machine learning', 'deep learning', 'neural network', 'NLP', 'GAN']\n",
        "    irrelevant_words = ['portfolio', 'personal website', 'tutorial', 'blog']\n",
        "    return (any(word in readme_content.lower() for word in keywords) and\n",
        "            not any(word in readme_content.lower() for word in irrelevant_words))\n",
        "\n",
        "def has_tool_related_files(repo_files):\n",
        "    tool_files = ['requirements.txt', 'setup.py', 'Dockerfile', '.ipynb', 'README.md']\n",
        "    return any(file in repo_files for file in tool_files)\n",
        "\n",
        "def filter_repositories(repositories):\n",
        "    filtered_repos = []\n",
        "    for repo in repositories:\n",
        "        readme_url = repo['url'] + \"/readme\"\n",
        "        response = requests.get(readme_url, headers={\n",
        "            'Authorization': 'token 這是GITHUBAPIKEY貼上的地方',\n",
        "            'Accept': 'application/vnd.github.v3.raw'  # 獲取原始 README 內容\n",
        "        })\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            readme_content = response.text\n",
        "            if is_ai_related(readme_content):\n",
        "                repo_files_url = repo['url'] + \"/contents\"\n",
        "                files_response = requests.get(repo_files_url, headers={\n",
        "                    'Authorization': 'token 這是GITHUBAPIKEY貼上的地方'\n",
        "                })\n",
        "\n",
        "                if files_response.status_code == 200:\n",
        "                    repo_files = [file['name'] for file in files_response.json()]\n",
        "                    if has_tool_related_files(repo_files):\n",
        "                        filtered_repos.append(repo)\n",
        "        else:\n",
        "            print(f\"Could not fetch README for {repo['name']}: {response.status_code}\")\n",
        "    return filtered_repos\n",
        "\n",
        "def save_to_csv(repositories, file_name):\n",
        "    # 定義 CSV 欄位\n",
        "    fields = ['created_at', 'name', 'html_url', 'topics']\n",
        "\n",
        "    # 寫入 CSV\n",
        "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=fields)\n",
        "        writer.writeheader()\n",
        "        for repo in repositories:\n",
        "            writer.writerow({\n",
        "                'created_at': repo['created_at'],\n",
        "                'name': repo['name'],\n",
        "                'html_url': repo['html_url'],\n",
        "                'topics': ', '.join(repo.get('topics', []))  # 標籤類別\n",
        "            })\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"正在抓取過去一週內的人工智慧相關資料庫...\")\n",
        "    repos = fetch_repositories()\n",
        "    if repos:\n",
        "        print(\"正在篩選真正的人工智慧工具資料庫...\")\n",
        "        filtered_repos = filter_repositories(repos)\n",
        "        if filtered_repos:\n",
        "            file_name = 'github_ai_repositories.csv'\n",
        "            save_to_csv(filtered_repos, file_name)\n",
        "            print(f\"已成功將 {len(filtered_repos)} 筆資料儲存到 {file_name}\")\n",
        "        else:\n",
        "            print(\"未找到符合條件的人工智慧工具資料庫。\")\n",
        "    else:\n",
        "        print(\"未找到相關資料庫或請求失敗。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HUGGINGGACE 關於AI 爬蟲一周份量"
      ],
      "metadata": {
        "id": "LDy5S0zDlFLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil.parser import parse\n",
        "\n",
        "def fetch_models():\n",
        "    # Hugging Face API URL\n",
        "    base_url = \"https://huggingface.co/api/models\"\n",
        "\n",
        "    # 計算 1 個月前的日期\n",
        "    one_month_ago = datetime.now() - timedelta(days=30)\n",
        "\n",
        "    # 查詢條件\n",
        "    params = {\n",
        "        'sort': 'downloads',  # 依據下載量排序\n",
        "        'direction': -1,      # 遞減排序\n",
        "        'limit': 100          # 每次請求最多獲取 100 筆\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        'Authorization': 'Bearer HF_TOKEN'  # 替換為您的 Hugging Face API Token\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, headers=headers, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        models = response.json()\n",
        "        print(f\"獲取到 {len(models)} 筆模型資料。\")  # 調試日誌\n",
        "\n",
        "        # 過濾 1 個月內新上傳的模型\n",
        "        recent_models = []\n",
        "        for model in models:\n",
        "            last_modified_str = model.get('lastModified', None)\n",
        "            if last_modified_str:\n",
        "                try:\n",
        "                    last_modified = parse(last_modified_str)\n",
        "                    if last_modified >= one_month_ago:\n",
        "                        recent_models.append(model)\n",
        "                except Exception as e:\n",
        "                    print(f\"解析日期失敗: {last_modified_str}, 錯誤: {e}\")\n",
        "            else:\n",
        "                print(f\"模型 {model['modelId']} 沒有 'lastModified' 欄位，將其標記為 '未知'。\")\n",
        "                model['lastModified'] = 'Unknown'\n",
        "                recent_models.append(model)\n",
        "\n",
        "        print(f\"過濾後剩餘 {len(recent_models)} 筆模型資料（1 個月內更新或標記為未知）。\")\n",
        "        return recent_models\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code} - {response.text}\")\n",
        "        return []\n",
        "\n",
        "def save_to_csv(models, file_name):\n",
        "    # 定義 CSV 欄位\n",
        "    fields = ['modelId', 'author', 'lastModified', 'downloads', 'tags']\n",
        "\n",
        "    # 寫入 CSV\n",
        "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=fields)\n",
        "        writer.writeheader()\n",
        "        for model in models:\n",
        "            writer.writerow({\n",
        "                'modelId': model['modelId'],\n",
        "                'author': model.get('author', 'Unknown'),\n",
        "                'lastModified': model.get('lastModified', 'Unknown'),\n",
        "                'downloads': model.get('downloads', 0),\n",
        "                'tags': ', '.join(model.get('tags', []))\n",
        "            })\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"正在抓取 Hugging Face 過去 1 個月內的模型資料...\")\n",
        "    models = fetch_models()\n",
        "    if models:\n",
        "        file_name = 'huggingface_recent_models.csv'\n",
        "        save_to_csv(models, file_name)\n",
        "        print(f\"已成功將 {len(models)} 筆模型資料儲存到 {file_name}\")\n",
        "    else:\n",
        "        print(\"未找到相關模型或請求失敗。\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym9PMaTcoFiS",
        "outputId": "c6d07005-aaaa-4f2c-8e34-22eb565a4015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在抓取 Hugging Face 過去 1 個月內的模型資料...\n",
            "獲取到 100 筆模型資料。\n",
            "模型 sentence-transformers/all-MiniLM-L6-v2 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 microsoft/resnet-50 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 google-bert/bert-base-uncased 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 FacebookAI/xlm-roberta-large 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 timm/resnet50.a1_in1k 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 openai/clip-vit-large-patch14 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 distributed/optimized-gpt2-2b 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 distributed/optimized-gpt2-1b 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 sentence-transformers/all-mpnet-base-v2 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 openai/clip-vit-base-patch32 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 jonatasgrosman/wav2vec2-large-xlsr-53-english 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 FacebookAI/roberta-base 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 ByteDance/AnimateDiff-Lightning 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 pyannote/segmentation-3.0 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 google-bert/bert-base-multilingual-uncased 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 distilbert/distilbert-base-uncased 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 FacebookAI/xlm-roberta-base 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 FacebookAI/roberta-large 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 pyannote/wespeaker-voxceleb-resnet34-LM 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 openai/clip-vit-base-patch16 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 pyannote/speaker-diarization-3.1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 microsoft/codebert-base 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 openai-community/gpt2 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 CIDAS/clipseg-rd64-refined 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 sentence-transformers/multi-qa-MiniLM-L6-cos-v1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 pyannote/segmentation 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 bigscience/bloomz-560m 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 sentence-transformers/all-MiniLM-L12-v2 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 M-CLIP/XLM-Roberta-Large-Vit-B-32 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 google/electra-base-discriminator 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 laion/CLIP-ViT-B-32-laion2B-s34B-b79K 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 facebook/dinov2-base 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 sentence-transformers/paraphrase-MiniLM-L6-v2 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 openai/clip-vit-large-patch14-336 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 google-bert/bert-base-multilingual-cased 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 google-t5/t5-small 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 pyannote/speaker-diarization 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 google/vit-base-patch16-224-in21k 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 distilbert/distilbert-base-uncased-finetuned-sst-2-english 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 openai/whisper-small 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 BAAI/bge-small-en-v1.5 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 facebook/opt-125m 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 sentence-transformers/all-distilroberta-v1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 papluca/xlm-roberta-base-language-detection 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 facebook/mms-lid-256 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 microsoft/deberta-base 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 google-bert/bert-base-cased 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 princeton-nlp/sup-simcse-roberta-large 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 yosuke/bert-base-japanese-char 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 yikuan8/Clinical-Longformer 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 meta-llama/Llama-3.1-8B-Instruct 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 google/vit-base-patch16-224 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 albert/albert-base-v2 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 WinKawaks/vit-tiny-patch16-224 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 BAAI/bge-large-en-v1.5 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 laion/CLIP-ViT-B-16-laion2B-s34B-b88K 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 jonatasgrosman/wav2vec2-large-xlsr-53-russian 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 openai/whisper-large-v3 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 jonatasgrosman/wav2vec2-large-xlsr-53-portuguese 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 facebook/bart-large-cnn 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 emilyalsentzer/Bio_ClinicalBERT 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-7B-Instruct-v0.3 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 cross-encoder/ms-marco-MiniLM-L-6-v2 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 pyannote/embedding 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 neuralmind/bert-base-portuguese-cased 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-7B-Instruct-v0.2 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mattmdjaga/segformer_b2_clothes 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 facebook/bart-large-mnli 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 Falconsai/nsfw_image_detection 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 microsoft/table-transformer-detection 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 sentence-transformers/bert-base-nli-mean-tokens 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 stable-diffusion-v1-5/stable-diffusion-v1-5 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-7B-Instruct-v0.1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 unslothai/1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-7B-v0.1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mixtral-8x7B-Instruct-v0.1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 pyannote/speaker-diarization-3.0 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-Nemo-Instruct-2407 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mixtral-8x22B-Instruct-v0.1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 nvidia/parakeet-rnnt-1.1b 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-7B-v0.3 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 answerdotai/answerai-colbert-small-v1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Ministral-8B-Instruct-2410 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 allenai/longformer-base-4096 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mixtral-8x7B-v0.1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-Nemo-Base-2407 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-Large-Instruct-2407 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-Small-Instruct-2409 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Codestral-22B-v0.1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mathstral-7B-v0.1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mistral-Large-Instruct-2411 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 mistralai/Mixtral-8x22B-v0.1 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 dslim/bert-base-NER 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 meta-llama/Llama-3.2-11B-Vision-Instruct 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 Alibaba-NLP/gte-large-en-v1.5 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 adsabs/astroBERT 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 google-bert/bert-large-uncased 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "模型 w11wo/indonesian-roberta-base-posp-tagger 沒有 'lastModified' 欄位，將其標記為 '未知'。\n",
            "過濾後剩餘 100 筆模型資料（1 個月內更新或標記為未知）。\n",
            "已成功將 100 筆模型資料儲存到 huggingface_recent_models.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "後處理"
      ],
      "metadata": {
        "id": "M6FISifHN76c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def categorize_model(tags):\n",
        "    \"\"\"\n",
        "    根據 tags 將模型分類為 NLP、Computer Vision、Audio、Multimodal 或 Other。\n",
        "    \"\"\"\n",
        "    categories = {\n",
        "        'NLP': ['nlp', 'text-generation', 'translation', 'token-classification', 'question-answering', 'summarization'],\n",
        "        'Computer Vision': ['image-classification', 'object-detection', 'segmentation', 'image-generation'],\n",
        "        'Audio': ['audio', 'speech-recognition', 'text-to-speech', 'audio-classification'],\n",
        "        'Multimodal': ['multimodal', 'vision-language', 'image-captioning'],\n",
        "    }\n",
        "\n",
        "    for category, keywords in categories.items():\n",
        "        if any(tag in tags for tag in keywords):\n",
        "            return category\n",
        "    return 'Other'\n",
        "\n",
        "def process_csv(input_file, output_file):\n",
        "    \"\"\"\n",
        "    處理輸入的 CSV 文件，根據 tags 欄位分類模型類型，並輸出更新後的 CSV 文件。\n",
        "    \"\"\"\n",
        "    with open(input_file, mode='r', encoding='utf-8') as infile:\n",
        "        reader = csv.DictReader(infile)\n",
        "        rows = list(reader)\n",
        "\n",
        "    # 準備輸出字段，新增一個 \"type\" 欄位\n",
        "    fieldnames = reader.fieldnames + ['type']\n",
        "\n",
        "    with open(output_file, mode='w', newline='', encoding='utf-8') as outfile:\n",
        "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for row in rows:\n",
        "            tags = row['tags'].split(', ') if row['tags'] else []\n",
        "            row['type'] = categorize_model(tags)\n",
        "            writer.writerow(row)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = '/content/huggingface_ai_models.csv'\n",
        "    output_file = '/content/huggingface_ai_models_processed.csv'\n",
        "\n",
        "    print(f\"正在處理文件 {input_file}...\")\n",
        "    process_csv(input_file, output_file)\n",
        "    print(f\"分類完成，已將結果輸出到 {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koWRh_LEnX7o",
        "outputId": "f45e5863-073b-4161-99e9-49242b01523c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在處理文件 /content/huggingface_ai_models.csv...\n",
            "分類完成，已將結果輸出到 /content/huggingface_ai_models_processed.csv\n"
          ]
        }
      ]
    }
  ]
}